# ç¬¬å…­ç« ï¼šAI é©±åŠ¨çš„å®¹å™¨å®‰å…¨ä¸æœ€ä½³å®è·µ (Chapter 6: AI-Driven Security & Best Practices)

> æ„å»ºå®‰å…¨çš„å®¹å™¨åŒ–åº”ç”¨ï¼Œè¿ç”¨ AI å·¥å…·è‡ªåŠ¨æ£€æµ‹æ¼æ´ï¼ŒæŒæ¡ä¾›åº”é“¾å®‰å…¨æœ€ä½³å®è·µ

---

å®¹å™¨åŒ–è™½ç„¶å¸¦æ¥äº†ä¾¿æ·æ€§,ä½†ä¹Ÿå¼•å…¥äº†æ–°çš„å®‰å…¨æŒ‘æˆ˜ã€‚ä»é•œåƒæ¼æ´åˆ°è¿è¡Œæ—¶å¨èƒ,ä»é…ç½®é”™è¯¯åˆ°ä¾›åº”é“¾æ”»å‡»,æ¯ä¸€ç¯éƒ½å¯èƒ½æˆä¸ºå®‰å…¨ç¼ºå£ã€‚æœ¬ç« å°†æ¢è®¨å¦‚ä½•åˆ©ç”¨ AI æŠ€æœ¯æ„å»ºå¤šå±‚æ¬¡çš„å®¹å™¨å®‰å…¨é˜²å¾¡ä½“ç³»,å¹¶ä»‹ç»ä¸šç•Œæœ€ä½³å®è·µã€‚

## 6.1 å®¹å™¨é•œåƒæ¼æ´æ‰«æï¼šAI è¯†åˆ« CVE

### 6.1.1 é•œåƒå®‰å…¨å¨èƒ

**å¸¸è§é—®é¢˜**ï¼š
1. **è¿‡æ—¶çš„åŸºç¡€é•œåƒ**ï¼šå¦‚ä½¿ç”¨ `ubuntu:16.04`ï¼ˆå·²åœæ­¢å®‰å…¨æ›´æ–°ï¼‰
2. **æ˜“å—æ”»å‡»çš„ä¾èµ–**ï¼šå¦‚ Log4Shellã€Heartbleed
3. **é…ç½®é”™è¯¯**ï¼šä»¥ root è¿è¡Œã€æš´éœ²æ•æ„Ÿç«¯å£
4. **æ¶æ„æ¤å…¥**ï¼šåé—¨ã€æŒ–çŸ¿ç¨‹åº

**çœŸå®æ¡ˆä¾‹**ï¼š
```dockerfile
# âŒ ä¸å®‰å…¨çš„ Dockerfile
FROM ubuntu:16.04  # è¿‡æ—¶ç‰ˆæœ¬
RUN apt-get update && apt-get install -y \
    libssl1.0.0  # åŒ…å« Heartbleed æ¼æ´
USER root  # ä»¥ root è¿è¡Œ
EXPOSE 22  # æš´éœ² SSH
```

### 6.1.2 ä¼ ç»Ÿæ¼æ´æ‰«æå·¥å…·

#### Trivyï¼ˆæ¨èï¼‰

```bash
# æ‰«æé•œåƒ
trivy image nginx:latest

# è¾“å‡ºç¤ºä¾‹
nginx:latest (alpine 3.14.0)
===========================
Total: 10 (CRITICAL: 2, HIGH: 5, MEDIUM: 3)

CVE-2021-44228 (Log4Shell)
CRITICAL
Package: log4j-core
Version: 2.14.0
Fixed Version: 2.17.1
```

#### Clair

```bash
# è¿è¡Œ Clair æœåŠ¡
docker run -d \
  -p 6060:6060 \
  -p 6061:6061 \
  quay.io/coreos/clair:latest
```

#### Anchore Engine

```bash
anchore-cli image add nginx:latest
anchore-cli image vuln nginx:latest all
```

### 6.1.3 AI å¢å¼ºæ¼æ´æ‰«æ

**ä¼ ç»Ÿæ‰«æçš„å±€é™**ï¼š
- ä¾èµ–å·²çŸ¥ CVE æ•°æ®åº“ï¼ˆæ»åæ€§ï¼‰
- é«˜è¯¯æŠ¥ç‡
- æ— æ³•æ£€æµ‹é›¶æ—¥æ¼æ´

**AI è§£å†³æ–¹æ¡ˆ**ï¼š

#### 1. åŸºäº ML çš„æ¼æ´é¢„æµ‹

```python
# ä½¿ç”¨æœºå™¨å­¦ä¹ é¢„æµ‹æ½œåœ¨æ¼æ´
from sklearn.ensemble import RandomForestClassifier
import numpy as np

class VulnerabilityPredictor:
    def __init__(self):
        self.model = RandomForestClassifier(n_estimators=100)
        
    def extract_features(self, package):
        """æå–åŒ…ç‰¹å¾"""
        return [
            package.age_days,           # ç‰ˆæœ¬å¹´é¾„
            package.update_frequency,   # æ›´æ–°é¢‘ç‡
            package.dependencies_count, # ä¾èµ–æ•°é‡
            package.cve_history_count,  # å†å²æ¼æ´æ•°
            package.github_stars,       # æµè¡Œåº¦
        ]
    
    def predict_risk(self, package):
        features = self.extract_features(package)
        risk_score = self.model.predict_proba([features])[0][1]
        return risk_score  # 0.0 - 1.0
        
# ä½¿ç”¨ç¤ºä¾‹
predictor = VulnerabilityPredictor()
for package in image.packages:
    risk = predictor.predict_risk(package)
    if risk > 0.8:
        alert(f"High risk package: {package.name}")
```

#### 2. LLM è¾…åŠ©æ¼æ´åˆ†æ

```python
# ä½¿ç”¨ GPT-4 åˆ†æå¤æ‚æ¼æ´
import openai

def analyze_vulnerability_with_ai(cve_id, image_context):
    prompt = f"""
    åˆ†æä»¥ä¸‹å®¹å™¨é•œåƒä¸­çš„æ¼æ´ï¼š
    
    CVE ID: {cve_id}
    é•œåƒä¿¡æ¯: {image_context}
    
    è¯·æä¾›ï¼š
    1. æ¼æ´åˆ©ç”¨éš¾åº¦è¯„ä¼°
    2. åœ¨å®¹å™¨ç¯å¢ƒä¸­çš„å®é™…é£é™©
    3. ä¿®å¤å»ºè®®ï¼ˆè€ƒè™‘å…¼å®¹æ€§ï¼‰
    4. ä¸´æ—¶ç¼“è§£æªæ–½
    """
    
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )
    
    return response.choices[0].message.content

# ç¤ºä¾‹è¾“å‡º
ai_analysis = analyze_vulnerability_with_ai(
    "CVE-2021-44228",
    "Alpine-based Java application"
)
print(ai_analysis)
```

**AI è¾“å‡ºç¤ºä¾‹**ï¼š
```
æ¼æ´åˆ†æ - CVE-2021-44228 (Log4Shell)

1. åˆ©ç”¨éš¾åº¦: â­â­ (ç®€å•)
   åªéœ€å‘é€ç‰¹åˆ¶çš„ JNDI æŸ¥è¯¢å³å¯è§¦å‘

2. å®¹å™¨ç¯å¢ƒé£é™©: ğŸ”´ é«˜å±
   è™½ç„¶å®¹å™¨éš”ç¦»äº†æ–‡ä»¶ç³»ç»Ÿï¼Œä½†æ”»å‡»è€…å¯ä»¥ï¼š
   - é€šè¿‡ JNDI å‘èµ· LDAP æŸ¥è¯¢
   - ä¸‹è½½æ¶æ„ .class æ–‡ä»¶æ‰§è¡Œ
   - è·å–å®¹å™¨å†…æ•æ„Ÿç¯å¢ƒå˜é‡
   
3. ä¿®å¤å»ºè®®:
   âœ… å‡çº§ log4j-core åˆ° 2.17.1+
   âš ï¸  æ£€æŸ¥ç¬¬ä¸‰æ–¹ä¾èµ–æ˜¯å¦ä¹ŸåŒ…å«æ˜“å—æ”»å‡»ç‰ˆæœ¬
   
4. ä¸´æ—¶ç¼“è§£:
   - è®¾ç½®ç¯å¢ƒå˜é‡: LOG4J_FORMAT_MSG_NO_LOOKUPS=true
   - ç§»é™¤ JndiLookup.class: zip -q -d log4j-core-*.jar org/apache/logging/log4j/core/lookup/JndiLookup.class
```

#### 3. å¼‚å¸¸ç‰¹å¾æ£€æµ‹

```python
# ä½¿ç”¨æ— ç›‘ç£å­¦ä¹ æ£€æµ‹å¼‚å¸¸é•œåƒå±‚
from sklearn.cluster import DBSCAN
import numpy as np

class AnomalyDetector:
    def __init__(self):
        self.dbscan = DBSCAN(eps=0.5, min_samples=5)
        
    def detect_malicious_layers(self, image_layers):
        features = []
        for layer in image_layers:
            features.append([
                layer.size,
                layer.file_count,
                self.entropy(layer.content),  # é«˜ç†µå¯èƒ½è¡¨ç¤ºåŠ å¯†/æ··æ·†
                self.has_hidden_files(layer),
                self.has_network_tools(layer),  # å¦‚ nc, nmap
            ])
        
        # èšç±»åˆ†æ
        clusters = self.dbscan.fit_predict(features)
        
        # æ ‡è®°ä¸ºå¼‚å¸¸å€¼çš„å±‚ï¼ˆcluster_id=-1ï¼‰
        anomalies = [i for i, c in enumerate(clusters) if c == -1]
        return anomalies
    
    def entropy(self, data):
        """è®¡ç®—æ•°æ®ç†µï¼ˆæ£€æµ‹åŠ å¯†/æ··æ·†ï¼‰"""
        import math
        prob = [data.count(byte) / len(data) for byte in set(data)]
        return -sum(p * math.log2(p) for p in prob if p > 0)
```

### 6.1.4 è‡ªåŠ¨åŒ–æ¼æ´ä¿®å¤

**AI ç”Ÿæˆä¿®å¤è¡¥ä¸**ï¼š

```python
def generate_dockerfile_patch(vulnerability, current_dockerfile):
    prompt = f"""
    ä»¥ä¸‹ Dockerfile å­˜åœ¨æ¼æ´ï¼š{vulnerability.description}
    
    å½“å‰ Dockerfile:
    {current_dockerfile}
    
    è¯·ç”Ÿæˆä¿®å¤åçš„ Dockerfileï¼Œç¡®ä¿ï¼š
    1. ä¿®å¤æ¼æ´
    2. ä¿æŒåŠŸèƒ½å…¼å®¹
    3. éµå¾ªæœ€ä½³å®è·µ
    
    åªè¾“å‡ºä¿®æ”¹åçš„ Dockerfileï¼Œä¸è¦è§£é‡Šã€‚
    """
    
    fixed_dockerfile = llm.generate(prompt)
    return fixed_dockerfile

# ç”Ÿæˆ Pull Request
vulnerability = scan_image("myapp:latest")
fixed_df = generate_dockerfile_patch(vulnerability, read_file("Dockerfile"))
create_pr(title="Fix CVE-2021-44228", body=fixed_df)
```

---

## 6.2 è¿è¡Œæ—¶å®‰å…¨ç›‘æ§ï¼šåŸºäº AI çš„å¼‚å¸¸è¡Œä¸ºæ£€æµ‹

### 6.2.1 è¿è¡Œæ—¶å¨èƒç±»å‹

| å¨èƒç±»å‹ | ç¤ºä¾‹ | å±å®³ |
|---------|------|------|
| **å®¹å™¨é€ƒé€¸** | åˆ©ç”¨å†…æ ¸æ¼æ´è®¿é—®ä¸»æœº | å®Œå…¨æ§åˆ¶ä¸»æœº |
| **æ¨ªå‘ç§»åŠ¨** | ä»ä¸€ä¸ªå®¹å™¨æ”»å‡»å…¶ä»–å®¹å™¨ | æ‰©å¤§æ”»å‡»é¢ |
| **æ•°æ®çªƒå–** | è¯»å–æ•æ„Ÿæ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡ | æ³„éœ²æœºå¯† |
| **èµ„æºæ»¥ç”¨** | æŒ–çŸ¿ç¨‹åºæ¶ˆè€— CPU | è´¹ç”¨å¢åŠ  |
| **æ¶æ„ç½‘ç»œæ´»åŠ¨** | C&C é€šä¿¡ã€DDoS æ”»å‡» | æ³•å¾‹é£é™© |

### 6.2.2 ä¼ ç»Ÿè¿è¡Œæ—¶é˜²æŠ¤

#### Seccompï¼ˆç³»ç»Ÿè°ƒç”¨è¿‡æ»¤ï¼‰

```json
{
  "defaultAction": "SCMP_ACT_ERRNO",
  "architectures": ["SCMP_ARCH_X86_64"],
  "syscalls": [
    {
      "names": ["read", "write", "open", "close"],
      "action": "SCMP_ACT_ALLOW"
    },
    {
      "names": ["chmod", "chown"],
      "action": "SCMP_ACT_ERRNO"
    }
  ]
}
```

#### AppArmor / SELinux

```bash
# AppArmor é…ç½®ç¤ºä¾‹
profile docker-nginx flags=(attach_disconnected,mediate_deleted) {
  #include <abstractions/base>
  
  network inet tcp,
  network inet udp,
  
  deny /proc/** w,
  deny /sys/** w,
}
```

### 6.2.3 AI å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ

#### ç³»ç»Ÿè°ƒç”¨åºåˆ—åˆ†æï¼ˆLSTMï¼‰

```python
import tensorflow as tf

class SyscallAnomalyDetector:
    def __init__(self):
        # LSTM æ¨¡å‹å­¦ä¹ æ­£å¸¸ç³»ç»Ÿè°ƒç”¨æ¨¡å¼
        self.model = tf.keras.Sequential([
            tf.keras.layers.Embedding(input_dim=400, output_dim=64),
            tf.keras.layers.LSTM(128, return_sequences=True),
            tf.keras.layers.LSTM(64),
            tf.keras.layers.Dense(1, activation='sigmoid')
        ])
        
    def train(self, normal_syscall_sequences):
        """è®­ç»ƒé˜¶æ®µï¼šå­¦ä¹ æ­£å¸¸è¡Œä¸º"""
        X, y = self.prepare_data(normal_syscall_sequences)
        self.model.fit(X, y, epochs=10)
        
    def detect(self, syscall_sequence):
        """æ£€æµ‹é˜¶æ®µï¼šè¯†åˆ«å¼‚å¸¸"""
        anomaly_score = self.model.predict([syscall_sequence])[0][0]
        
        if anomaly_score > 0.8:
            return {
                "alert": True,
                "confidence": anomaly_score,
                "reason": self.explain_anomaly(syscall_sequence)
            }
        return {"alert": False}
    
    def explain_anomaly(self, sequence):
        """è§£é‡Šä¸ºä»€ä¹ˆæ ‡è®°ä¸ºå¼‚å¸¸"""
        # ä½¿ç”¨ SHAP æˆ– LIME è§£é‡Šæ¨¡å‹å†³ç­–
        rare_syscalls = self.find_rare_calls(sequence)
        return f"æ£€æµ‹åˆ°ç½•è§ç³»ç»Ÿè°ƒç”¨åºåˆ—: {rare_syscalls}"

# éƒ¨ç½²
detector = SyscallAnomalyDetector()
detector.train(load_normal_traces())

# å®æ—¶ç›‘æ§
while True:
    syscalls = monitor_container("app-container")
    result = detector.detect(syscalls)
    if result["alert"]:
        quarantine_container("app-container")
        alert_security_team(result)
```

#### ç½‘ç»œæµé‡å¼‚å¸¸æ£€æµ‹

```python
class NetworkAnomalyDetector:
    def __init__(self):
        self.autoencoder = self.build_autoencoder()
        
    def build_autoencoder(self):
        """ä½¿ç”¨è‡ªç¼–ç å™¨æ£€æµ‹å¼‚å¸¸æµé‡æ¨¡å¼"""
        encoder = tf.keras.Sequential([
            tf.keras.layers.Dense(64, activation='relu'),
            tf.keras.layers.Dense(32, activation='relu'),
            tf.keras.layers.Dense(16, activation='relu'),
        ])
        
        decoder = tf.keras.Sequential([
            tf.keras.layers.Dense(32, activation='relu'),
            tf.keras.layers.Dense(64, activation='relu'),
            tf.keras.layers.Dense(128, activation='sigmoid'),
        ])
        
        return tf.keras.Sequential([encoder, decoder])
    
    def train(self, normal_network_traffic):
        """å­¦ä¹ æ­£å¸¸æµé‡çš„ç‰¹å¾"""
        self.autoencoder.fit(normal_network_traffic, normal_network_traffic)
        
    def detect_anomaly(self, traffic):
        """é‡æ„è¯¯å·®é«˜ = å¼‚å¸¸"""
        reconstructed = self.autoencoder.predict([traffic])
        mse = np.mean((traffic - reconstructed) ** 2)
        
        if mse > self.threshold:
            return {
                "alert": True,
                "mse": float(mse),
                "suspicious_features": self.analyze_traffic(traffic)
            }
        return {"alert": False}
    
    def analyze_traffic(self, traffic):
        """åˆ†æå¼‚å¸¸æµé‡ç‰¹å¾"""
        features = []
        if traffic.unexpected_port:
            features.append(f"Unusual port: {traffic.port}")
        if traffic.high_frequency:
            features.append("DDoS-like pattern detected")
        if traffic.unknown_destination:
            features.append(f"C&C server communication: {traffic.dest_ip}")
        return features
```

### 6.2.4 Falcoï¼šäº‘åŸç”Ÿè¿è¡Œæ—¶å®‰å…¨

```yaml
# Falco è§„åˆ™ç¤ºä¾‹
- rule: Write below root
  desc: Detect write operations below root directory
  condition: >
    container and
    evt.type in (open,openat) and
    evt.dir=< and
    fd.name startswith /
  output: >
    File opened for writing in root directory
    (user=%user.name command=%proc.cmdline file=%fd.name)
  priority: WARNING

# AI å¢å¼º Falco
- macro: ai_predicted_malicious
  condition: >
    ml_model.predict(proc.cmdline, proc.cwd, proc.pname) > 0.9

- rule: AI Detected Malicious Process
  desc: ML model flagged process as suspicious
  condition: >
    spawned_process and
    ai_predicted_malicious
  output: "AI Alert: Suspicious process (cmd=%proc.cmdline)"
  priority: CRITICAL
```

---

## 6.3 Dockerfile æœ€ä½³å®è·µï¼šAI è¾…åŠ©ç¼–å†™ä¸å®¡æŸ¥

### 6.3.1 å¸¸è§ Dockerfile å®‰å…¨é—®é¢˜

| é—®é¢˜ | ç¤ºä¾‹ | é£é™© |
|------|------|------|
| **ä»¥ root è¿è¡Œ** | æ—  `USER` æŒ‡ä»¤ | å®¹å™¨é€ƒé€¸åè·å¾—ä¸»æœº root |
| **æš´éœ²æ•æ„Ÿç«¯å£** | `EXPOSE 22 3306` | å¢åŠ æ”»å‡»é¢ |
| **æ³„éœ²å¯†é’¥** | `ENV API_KEY=xxx` | ä»£ç æ³„éœ²è¿å¸¦å¯†é’¥æ³„éœ² |
| **ä½¿ç”¨ latest æ ‡ç­¾** | `FROM nginx:latest` | ä¸å¯é‡ç°æ„å»º |
| **å®‰è£…ä¸å¿…è¦å·¥å…·** | `apt-get install curl wget` | è¢«åˆ©ç”¨ä¸ºæ”»å‡»å·¥å…· |

### 6.3.2 å®‰å…¨ Dockerfile æ¨¡æ¿

```dockerfile
# âœ… å®‰å…¨çš„ Dockerfile ç¤ºä¾‹

# ä½¿ç”¨ç‰¹å®šç‰ˆæœ¬æ ‡ç­¾ï¼ˆé¿å… latestï¼‰
FROM python:3.11-slim-bookworm

# åˆ›å»ºé root ç”¨æˆ·
RUN groupadd -r appuser && useradd -r -g appuser appuser

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# ä»…å¤åˆ¶å¿…è¦æ–‡ä»¶ï¼ˆéµå¾ªæœ€å°æƒé™åŸåˆ™ï¼‰
COPY --chown=appuser:appuser requirements.txt .

# å®‰è£…ä¾èµ–ï¼ˆåœ¨åŒä¸€å±‚æ¸…ç†ç¼“å­˜ï¼‰
RUN pip install --no-cache-dir -r requirements.txt && \
    rm -rf /root/.cache

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY --chown=appuser:appuser . .

# åˆ‡æ¢åˆ°é root ç”¨æˆ·
USER appuser

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s \
  CMD curl -f http://localhost:8000/health || exit 1

# ä»…æš´éœ²å¿…è¦ç«¯å£
EXPOSE 8000

# ä½¿ç”¨ exec æ ¼å¼ï¼ˆæ­£ç¡®å¤„ç†ä¿¡å·ï¼‰
CMD ["python", "app.py"]
```

### 6.3.3 AI è¾…åŠ© Dockerfile å®¡æŸ¥

#### prompt é©±åŠ¨çš„å®¡æŸ¥

```python
def ai_review_dockerfile(dockerfile_content):
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªå®¹å™¨å®‰å…¨ä¸“å®¶ã€‚è¯·å®¡æŸ¥ä»¥ä¸‹ Dockerfileï¼Œä»å®‰å…¨è§’åº¦æŒ‡å‡ºé—®é¢˜ï¼š
    
    {dockerfile_content}
    
    æ£€æŸ¥é¡¹ï¼š
    1. æ˜¯å¦ä½¿ç”¨ root ç”¨æˆ·è¿è¡Œ
    2. æ˜¯å¦åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼ˆå¯†é’¥ã€å¯†ç ï¼‰
    3. åŸºç¡€é•œåƒæ˜¯å¦è¿‡æ—¶
    4. æ˜¯å¦å®‰è£…äº†ä¸å¿…è¦çš„å·¥å…·
    5. å±‚æ•°æ˜¯å¦å¯ä»¥ä¼˜åŒ–
    6. æ˜¯å¦éµå¾ªæœ€ä½³å®è·µ
    
    å¯¹æ¯ä¸ªé—®é¢˜ï¼Œæä¾›ï¼š
    - ä¸¥é‡ç¨‹åº¦ï¼ˆCritical/High/Medium/Lowï¼‰
    - å…·ä½“ä½ç½®ï¼ˆè¡Œå·ï¼‰
    - ä¿®å¤å»ºè®®
    
    è¾“å‡ºæ ¼å¼ï¼šJSON
    """
    
    response = llm.generate(prompt)
    issues = json.loads(response)
    
    return issues

# ç¤ºä¾‹è¾“å‡º
review_result = ai_review_dockerfile(read_file("Dockerfile"))
```

**AI è¾“å‡º**ï¼š
```json
[
  {
    "severity": "Critical",
    "line": 12,
    "issue": "Running as root user",
    "description": "Container will run as root (UID 0), increasing risk if container is compromised",
    "fix": "Add:\nRUN useradd -m -u 1000 appuser\nUSER appuser"
  },
  {
    "severity": "High",
    "line": 5,
    "issue": "Hardcoded secret",
    "description": "API key exposed in environment variable",
    "fix": "Use Docker secrets or external secret management:\ndocker run --env-file .env myapp"
  },
  {
    "severity": "Medium",
    "line": 8,
    "issue": "Inefficient layering",
    "description": "Multiple RUN commands can be merged",
    "fix": "Combine:\nRUN apt-get update && \\\n    apt-get install -y curl && \\\n    rm -rf /var/lib/apt/lists/*"
  }
]
```

#### è‡ªåŠ¨ç”Ÿæˆå®‰å…¨ Dockerfile

```python
def generate_secure_dockerfile(app_type, requirements):
    prompt = f"""
    ä¸º {app_type} åº”ç”¨ç”Ÿæˆä¸€ä¸ªç”Ÿäº§çº§çš„å®‰å…¨ Dockerfileã€‚
    
    éœ€æ±‚ï¼š
    - ç¼–ç¨‹è¯­è¨€ï¼š{requirements.language}
    - ä¾èµ–ï¼š{requirements.dependencies}
    - ç«¯å£ï¼š{requirements.port}
    
    è¦æ±‚ï¼š
    1. å¤šé˜¶æ®µæ„å»ºï¼ˆåˆ†ç¦»æ„å»ºå’Œè¿è¡Œç¯å¢ƒï¼‰
    2. ä½¿ç”¨é root ç”¨æˆ·
    3. æœ€å°åŒ–é•œåƒä½“ç§¯
    4. åŒ…å«å¥åº·æ£€æŸ¥
    5. ä½¿ç”¨ç‰¹å®šç‰ˆæœ¬æ ‡ç­¾
    
    åªè¾“å‡º Dockerfileï¼Œä¸è¦è§£é‡Šã€‚
    """
    
    return llm.generate(prompt)

# ä½¿ç”¨
dockerfile = generate_secure_dockerfile(
    app_type="web_api",
    requirements={
        "language": "Python 3.11",
        "dependencies": ["flask", "psycopg2"],
        "port": 5000
    }
)

print(dockerfile)
```

---

## 6.4 ä¾›åº”é“¾å®‰å…¨ï¼šç­¾åä¸éªŒè¯ (Notary / Cosign)

### 6.4.1 ä¾›åº”é“¾æ”»å‡»å¨èƒ

**çœŸå®æ¡ˆä¾‹**ï¼š
- **SolarWinds (2020)**ï¼šæ¶æ„ä»£ç æ¤å…¥æ„å»ºæµç¨‹
- **Codecov (2021)**ï¼šBash Uploader è„šæœ¬è¢«ç¯¡æ”¹
- **Docker Hub (2019)**ï¼š17 ä¸ªé•œåƒè¢«æ¤å…¥æŒ–çŸ¿ç¨‹åº

**æ”»å‡»å‘é‡**ï¼š
```mermaid
graph LR
    A[å¼€å‘è€…æœºå™¨] --> B[CI/CD ç³»ç»Ÿ]
    B --> C[é•œåƒæ„å»º]
    C --> D[Registry]
    D --> E[ç”Ÿäº§ç¯å¢ƒ]
    
    X1[æ¶æ„ä»£ç æ³¨å…¥] -.-> A
    X2[CI é…ç½®ç¯¡æ”¹] -.-> B
    X3[ä¸­é—´äººæ”»å‡»] -.-> D
    
    style X1 fill:#ffe1e1
    style X2 fill:#ffe1e1
    style X3 fill:#ffe1e1
```

### 6.4.2 Docker Content Trust (DCT)

```bash
# å¯ç”¨ DCT
export DOCKER_CONTENT_TRUST=1

# æ¨é€é•œåƒï¼ˆè‡ªåŠ¨ç­¾åï¼‰
docker push myregistry.com/app:v1.0
# ç”Ÿæˆå¯†é’¥å¯¹ï¼Œæç¤ºè¾“å…¥å¯†ç 

# æ‹‰å–é•œåƒï¼ˆéªŒè¯ç­¾åï¼‰
docker pull myregistry.com/app:v1.0
# å¦‚æœç­¾åæ— æ•ˆï¼Œæ‹‰å–å¤±è´¥
```

**å¯†é’¥ç®¡ç†**ï¼š
```bash
~/.docker/trust/
â”œâ”€â”€ private/
â”‚   â”œâ”€â”€ root_keys/
â”‚   â””â”€â”€ tuf_keys/
â””â”€â”€ tuf/
    â””â”€â”€ myregistry.com/
        â””â”€â”€ app/
            â””â”€â”€ metadata/
```

### 6.4.3 Sigstore Cosignï¼ˆç°ä»£ç­¾åæ–¹æ¡ˆï¼‰

```bash
# å®‰è£… Cosign
brew install cosign

# ç”Ÿæˆå¯†é’¥å¯¹
cosign generate-key-pair

# ç­¾åé•œåƒ
cosign sign --key cosign.key myregistry.com/app:v1.0

# éªŒè¯ç­¾å
cosign verify --key cosign.pub myregistry.com/app:v1.0

# ä½¿ç”¨ keyless ç­¾åï¼ˆOIDCï¼‰
cosign sign myregistry.com/app:v1.0
# æµè§ˆå™¨æ‰“å¼€ OAuth æµç¨‹ï¼ˆGitHub/Google ç™»å½•ï¼‰
```

### 6.4.4 SBOMï¼ˆè½¯ä»¶ç‰©æ–™æ¸…å•ï¼‰

```bash
# ä½¿ç”¨ Syft ç”Ÿæˆ SBOM
syft packages nginx:latest -o json > sbom.json

# ä½¿ç”¨ Grype æ ¹æ® SBOM æ‰«ææ¼æ´
grype sbom:./sbom.json

# å°† SBOM é™„åŠ åˆ°é•œåƒï¼ˆCosignï¼‰
cosign attach sbom --sbom sbom.json myregistry.com/app:v1.0
```

**SBOM ç¤ºä¾‹**ï¼ˆSPDX æ ¼å¼ï¼‰ï¼š
```json
{
  "spdxVersion": "SPDX-2.3",
  "name": "myapp",
  "packages": [
    {
      "name": "openssl",
      "versionInfo": "1.1.1k",
      "supplier": "Organization: OpenSSL",
      "filesAnalyzed": false,
      "externalRefs": [
        {
          "referenceType": "purl",
          "referenceLocator": "pkg:deb/ubuntu/openssl@1.1.1k"
        }
      ]
    }
  ]
}
```

### 6.4.5 AI é©±åŠ¨çš„ä¾›åº”é“¾åˆ†æ

```python
class SupplyChainAnalyzer:
    def __init__(self):
        self.risk_model = self.load_risk_model()
        
    def analyze_dependency_tree(self, sbom):
        """åˆ†æä¾èµ–æ ‘çš„å®‰å…¨é£é™©"""
        risks = []
        
        for package in sbom.packages:
            risk_score = self.assess_package_risk(package)
            
            if risk_score > 0.7:
                risks.append({
                    "package": package.name,
                    "score": risk_score,
                    "reasons": self.explain_risk(package)
                })
        
        return risks
    
    def assess_package_risk(self, package):
        features = [
            self.package_age(package),
            self.maintainer_reputation(package),
            self.cve_history_count(package),
            self.is_abandoned(package),  # æœ€åæ›´æ–°æ—¶é—´ > 2å¹´
            self.has_few_users(package),
        ]
        
        return self.risk_model.predict([features])[0]
    
    def explain_risk(self, package):
        """AI è§£é‡Šé£é™©åŸå› """
        prompt = f"""
        åˆ†æ {package.name} (v{package.version}) çš„ä¾›åº”é“¾é£é™©ï¼š
        
        - ç»´æŠ¤è€…ï¼š{package.maintainer}
        - æœ€åæ›´æ–°ï¼š{package.last_update}
        - å†å² CVE æ•°ï¼š{package.cve_count}
        - ä¸‹è½½é‡ï¼š{package.downloads}
        
        å¯èƒ½çš„é£é™©å› ç´ æ˜¯ä»€ä¹ˆï¼Ÿåº”è¯¥é‡‡å–ä»€ä¹ˆæªæ–½ï¼Ÿ
        """
        
        return llm.generate(prompt)

# ä½¿ç”¨
analyzer = SupplyChainAnalyzer()
sbom = load_sbom("myapp")
risks = analyzer.analyze_dependency_tree(sbom)

for risk in risks:
    print(f"âš ï¸  {risk['package']} (Score: {risk['score']:.2f})")
    print(risk['reasons'])
```

---

## 6.5 ç»¼åˆæ¡ˆä¾‹ï¼šæ„å»º AI å®‰å…¨æµæ°´çº¿

```mermaid
graph TB
    A[å¼€å‘è€…æ¨é€ä»£ç ] --> B[è§¦å‘ CI/CD]
    B --> C1[AI ä»£ç å®¡æŸ¥<br/>æ£€æµ‹å®‰å…¨æ¼æ´]
    C1 --> C2[æ„å»ºé•œåƒ]
    C2 --> C3[Trivy æ‰«æ<br/>+ AI é£é™©è¯„ä¼°]
    
    C3 --> D{é£é™©è¯„åˆ†}
    D -->|é«˜é£é™©| E[é˜»æ­¢éƒ¨ç½²<br/>å‘é€å‘Šè­¦]
    D -->|ä½é£é™©| F[Cosign ç­¾å]
    
    F --> G[æ¨é€åˆ° Registry]
    G --> H[ç”Ÿæˆ SBOM]
    H --> I[éƒ¨ç½²åˆ° K8s]
    
    I --> J[Falco è¿è¡Œæ—¶ç›‘æ§<br/>+ AI å¼‚å¸¸æ£€æµ‹]
    J --> K{æ£€æµ‹åˆ°å¨èƒ?}
    K -->|æ˜¯| L[è‡ªåŠ¨éš”ç¦»å®¹å™¨]
    K -->|å¦| M[æ­£å¸¸è¿è¡Œ]
    
    style E fill:#ffe1e1
    style L fill:#ffe1e1
    style M fill:#c8e6c9
```

**GitHub Actions å®ç°**ï¼š
```yaml
name: AI-Powered Security Pipeline

on: [push]

jobs:
  security-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      # 1. AI ä»£ç å®¡æŸ¥
      - name: AI Code Review
        run: |
          python scripts/ai_security_review.py \
            --files $(git diff --name-only HEAD^)
      
      # 2. æ„å»ºé•œåƒ
      - name: Build Image
        run: docker build -t myapp:${{ github.sha }} .
      
      # 3. Trivy æ‰«æ
      - name: Run Trivy
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: 'myapp:${{ github.sha }}'
          format: 'json'
          output: 'trivy-results.json'
      
      # 4. AI é£é™©è¯„ä¼°
      - name: AI Risk Assessment
        run: |
          python scripts/ai_risk_analyzer.py \
            --trivy-results trivy-results.json \
            --threshold 0.7
      
      # 5. ç­¾åé•œåƒ
      - name: Sign with Cosign
        if: success()
        run: |
          cosign sign --key ${{ secrets.COSIGN_KEY }} \
            myapp:${{ github.sha }}
      
      # 6. ç”Ÿæˆ SBOM
      - name: Generate SBOM
        run: syft packages myapp:${{ github.sha }} -o json > sbom.json
      
      # 7. æ¨é€
      - name: Push Image
        if: success()
        run: docker push myapp:${{ github.sha }}
```

---

## æ€»ç»“

å®¹å™¨å®‰å…¨æ˜¯ä¸€ä¸ªå¤šå±‚æ¬¡çš„é˜²å¾¡ä½“ç³»ï¼š

1. **é•œåƒå®‰å…¨**ï¼šAI å¢å¼ºçš„æ¼æ´æ‰«æ + è‡ªåŠ¨ä¿®å¤
2. **è¿è¡Œæ—¶å®‰å…¨**ï¼šML å¼‚å¸¸æ£€æµ‹ + Seccomp/AppArmor
3. **é…ç½®å®‰å…¨**ï¼šAI è¾…åŠ© Dockerfile å®¡æŸ¥
4. **ä¾›åº”é“¾å®‰å…¨**ï¼šç­¾åéªŒè¯ + SBOM + ä¾èµ–é£é™©åˆ†æ

**å…³é”®åŸåˆ™**ï¼š
- âœ… **æœ€å°æƒé™**ï¼šé root ç”¨æˆ·ã€æœ€å°åŒ–å·¥å…·å®‰è£…
- âœ… **æ·±åº¦é˜²å¾¡**ï¼šå¤šå±‚å®‰å…¨æ§åˆ¶
- âœ… **æŒç»­ç›‘æ§**ï¼šè¿è¡Œæ—¶å¼‚å¸¸æ£€æµ‹
- âœ… **è‡ªåŠ¨åŒ–**ï¼šAI é©±åŠ¨çš„å®‰å…¨æµæ°´çº¿

**ä¸‹ä¸€ç« é¢„å‘Š**ï¼šæˆ‘ä»¬å°†é€šè¿‡ä¸‰ä¸ªå®Œæ•´çš„å®æˆ˜é¡¹ç›®ï¼Œå°†å‰é¢å­¦åˆ°çš„çŸ¥è¯†ä»˜è¯¸å®è·µã€‚

**[>> è¿›å…¥ç¬¬ä¸ƒç« ](./07-hands-on-projects.md)**

---

**è´¡çŒ®è€…æ¬¢è¿**: å¦‚æœæ‚¨å¯¹æœ¬ç« èŠ‚æœ‰å†…å®¹è¡¥å……æˆ–å»ºè®®ï¼Œæ¬¢è¿æäº¤ PR æˆ– Issueï¼
